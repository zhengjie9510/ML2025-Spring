{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkELbiG6ogiG"
   },
   "source": [
    "# Understanding LLM / Transformers (You cannot run the code without saving a copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvlATdaN45U8"
   },
   "source": [
    "## Check the status of your GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FISzjhfg4vo6"
   },
   "source": [
    "## Installing **transformers** for further usage (please do not alter the version for stable usage of model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.47.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLvm_l4g4O9U"
   },
   "source": [
    "## Huggingface login\n",
    "\n",
    "### You need the huggingface token (hf_token) to login to huggingface and install the gemma model. Therefore make sure you create your huggingface token. (Described in the Google slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## TODO (Pre-requisites) ########################\n",
    "# replace `your_hf_token` with your huggingface token\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(\"token\")\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HY1e8Urn-qy8"
   },
   "source": [
    "## Download the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemma Model: https://huggingface.co/google/gemma-2-2b-it\n",
    "### Please accept the lincense to download the gemma model (As described on Google Slides)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"google/gemma-2-2b-it\"\n",
    "dtype = torch.float16\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4cI-w4lEqvz"
   },
   "source": [
    "## Q1: Chat template Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBlbhVN4BHVG"
   },
   "source": [
    "### Evaluation Model: https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "SCORING_MODEL = AutoModelForSequenceClassification.from_pretrained('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "SCORING_TOKENIZER = AutoTokenizer.from_pretrained('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "\n",
    "def calculate_coherence(question, answer, scoring_model=SCORING_MODEL, tokenizer=SCORING_TOKENIZER):\n",
    "  features = tokenizer([question], [answer], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "  scoring_model.eval()\n",
    "  with torch.no_grad():\n",
    "      scores = scoring_model(**features).logits.squeeze().item()\n",
    "  return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JFRJMWdMrHU"
   },
   "source": [
    "### Observe whether the chat template affects the model's output results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_from_prompt(prompt, tokenizer, model):\n",
    "  \"\"\"\n",
    "  generate the output from the prompt.\n",
    "  param:\n",
    "    prompt (str): the prompt inputted to the model\n",
    "    tokenizer   : the tokenizer that is used to encode / decode the input / output\n",
    "    model       : the model that is used to generate the output\n",
    "\n",
    "  return:\n",
    "    the response of the model\n",
    "  \"\"\"\n",
    "  print(\"========== Prompt inputted to the model ==========\\n\", prompt)\n",
    "\n",
    "  # Tokenize the prompt\n",
    "  input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "  ######################## TODO (Q1.1 ~ 1.4) ########################\n",
    "  ### You can refer to https://huggingface.co/google/gemma-2-2b-it for basic usage\n",
    "  ### Make sure to use 'do_sample=False' to get a deterministic response\n",
    "  ### Otherwise the coherence score may be different from the sample answer\n",
    "\n",
    "  # Generate response\n",
    "  output_ids =model.generate(input_ids = input_ids,do_sample=False,max_new_tokens=1000)\n",
    "  ###################################################################\n",
    "  if output_ids is not None and len(output_ids) > 0:\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "  else:\n",
    "    return \"Empty Response\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With chat template\n",
    "question = \"Please tell me about the key differences between supervised learning and unsupervised learning. Answer in 200 words.\"\n",
    "chat = [\n",
    "    {\"role\": \"user\", \"content\": question},\n",
    "]\n",
    "prompt_with_template = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "response_with_template = generate_text_from_prompt(prompt_with_template, tokenizer, model)\n",
    "\n",
    "# extract the real output from the model\n",
    "response_with_template = response_with_template.split('model\\n')[-1].strip('\\n').strip()\n",
    "\n",
    "print(\"========== Output ==========\\n\", response_with_template)\n",
    "score = calculate_coherence(question, response_with_template)\n",
    "print(f\"========== Coherence Score : {score:.4f}  ==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without chat template (directly using plain text)\n",
    "response_without_template = generate_text_from_prompt(question, tokenizer, model)\n",
    "\n",
    "# extract the real output from the model\n",
    "response_without_template = response_without_template.split(question.split(' ')[-1])[-1].strip('\\n').strip()\n",
    "print(\"========== Output ==========\\n\", response_without_template)\n",
    "score = calculate_coherence(question, response_without_template)\n",
    "print(f\"========== Coherence Score : {score:.4f}  ==========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YT8amEJSP-E"
   },
   "source": [
    "## Q2: Multi-turn conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "chat_history = []\n",
    "round = 0\n",
    "print(\"Chatbot: Hello! How can I assist you today? (Type 'exit' to quit)\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    round += 1\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "    chat_template_format_prompt = tokenizer.apply_chat_template(chat_history, tokenize=False, add_generation_prompt=True)\n",
    "    ######################## (Q2.1 ~ 2.3) ########################\n",
    "    # Observe the prompt with chat template format that was inputted to the model in the current round to answer Q2.1 ~ Q2.3.\n",
    "    print(f\"=== Prompt with chat template format inputted to the model on round {round} ===\\n{chat_template_format_prompt}\")\n",
    "    print(f\"===============================================\")\n",
    "    ###################################################################\n",
    "\n",
    "    inputs = tokenizer(chat_template_format_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    # Get logits instead of directly generating\n",
    "    with torch.no_grad():\n",
    "        outputs_p = model(**inputs)\n",
    "\n",
    "    logits = outputs_p.logits  # Logits of the model (raw scores before softmax)\n",
    "    last_token_logits = logits[:, -1, :]  # Take the logits of the last generated token\n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    probs = torch.nn.functional.softmax(last_token_logits, dim=-1)\n",
    "\n",
    "    # Get top-k tokens (e.g., 10)\n",
    "    top_k = 10\n",
    "    top_probs, top_indices = torch.topk(probs, top_k)\n",
    "\n",
    "    # Convert to numpy for plotting\n",
    "    top_probs = top_probs.cpu().squeeze().numpy()\n",
    "    top_indices = top_indices.cpu().squeeze().numpy()\n",
    "    top_tokens = [tokenizer.decode([idx]) for idx in top_indices]\n",
    "\n",
    "    # Plot probability distribution\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=top_probs, y=top_tokens, palette=\"coolwarm\")\n",
    "    plt.xlabel(\"Probability\")\n",
    "    plt.ylabel(\"Token\")\n",
    "    plt.title(\"Top Token Probabilities for Next Word\")\n",
    "    plt.show()\n",
    "\n",
    "    # Generate response\n",
    "    outputs = model.generate(**inputs, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id, do_sample=False)\n",
    "    response = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"Chatbot: {response}\")\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": response})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oo7JKIgp0Txd"
   },
   "source": [
    "## Q3: Tokenization of Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"你好，我的名字是Jason，你呢？\" #@param {type:\"string\"}\n",
    "\n",
    "######################## TODO (Q3.1 ~ 3.4) ########################\n",
    "### You can refer to https://huggingface.co/learn/nlp-course/en/chapter2/4?fw=pt for basic tokenizer usage\n",
    "### and https://huggingface.co/docs/transformers/en/main_classes/tokenizer for full tokenizer usage\n",
    "\n",
    "\n",
    "# Encode the sentence into token IDs without adding special tokens\n",
    "token_ids = tokenizer.encode(sentence, add_special_tokens=False)\n",
    "\n",
    "# Convert the token IDs back to their corresponding tokens (words or subwords)\n",
    "tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "###################################################################\n",
    "\n",
    "# Iterate through the tokens and their corresponding token IDs\n",
    "for t, t_id in zip(tokens, token_ids):\n",
    "    # Print the token and its index (ID)\n",
    "    print(f\"Token: {t}, token index: {t_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1ocRPtU0Txe"
   },
   "source": [
    "## Q4: Auto-regressive generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "max_generation_tokens = 30\n",
    "\n",
    "######################## TODO (Q4.3 ~ 4.6) ########################\n",
    "# Modify the value of k and p accordingly\n",
    "\n",
    "top_k = 10  # Set K for top-k sampling\n",
    "top_p = 0.6  # Set P for nucleus sampling\n",
    "###################################################################\n",
    "\n",
    "# Input prompt\n",
    "prompt = f\"Generate a paraphrase of the sentence 'Professor Hung-yi Lee is one of the best teachers in the domain of machine learning'. Just response with one sentence.\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "next_token_id = input_ids.input_ids.to(\"cuda\")\n",
    "attention_mask = input_ids.attention_mask.to(\"cuda\")\n",
    "cache_position = torch.arange(attention_mask.shape[1], device=\"cuda\")\n",
    "\n",
    "generated_sentences_top_k = []\n",
    "generated_sentences_top_p = []\n",
    "\n",
    "\n",
    "\n",
    "# Define the generation parameters\n",
    "generation_params = {\n",
    "    \"do_sample\": True,  # Enable sampling\n",
    "    \"max_length\": max_generation_tokens + len(input_ids.input_ids[0]),  # Total length including prompt\n",
    "    \"pad_token_id\": tokenizer.pad_token_id,  # Ensure padding token is set\n",
    "    \"eos_token_id\": tokenizer.eos_token_id,  # Ensure EOS token is set\n",
    "    \"bos_token_id\": tokenizer.bos_token_id,  # Ensure BOS token is set\n",
    "    \"attention_mask\": input_ids.attention_mask.to(\"cuda\"),  # Move attention mask to GPU\n",
    "    \"use_cache\": True,  # Enable caching\n",
    "    \"return_dict_in_generate\": True,  # Return generation outputs\n",
    "    \"output_scores\": False,  # Disable outputting scores\n",
    "}\n",
    "\n",
    "\n",
    "for method in [\"top-k\", \"top-p\"]:\n",
    "    for _ in trange(20):\n",
    "      if method == \"top-k\":\n",
    "        # Generate text using the model with top_k\n",
    "        generated_output = model.generate(\n",
    "            input_ids=input_ids.input_ids.to(\"cuda\"),\n",
    "            top_k=top_k,\n",
    "            **generation_params\n",
    "        )\n",
    "      elif method == \"top-p\":\n",
    "        # Generate text using the model with top_p\n",
    "        ######################## TODO (Q4.3 ~ 4.6) ########################\n",
    "        # Generate output from the model based on the input_ids and specified generation parameters\n",
    "        # You can refer to this documentation: https://huggingface.co/docs/transformers/en/main_classes/text_generation\n",
    "        # Hint: You can check how we generate the text with top_k\n",
    "\n",
    "        generated_output = model.generate(\n",
    "            input_ids=input_ids.input_ids.to(\"cuda\"),\n",
    "            top_p=top_p,\n",
    "            **generation_params\n",
    "        )\n",
    "        ###################################################################\n",
    "      else:\n",
    "        raise NotImplementedError()\n",
    "      # Decode the generated tokens\n",
    "      generated_tokens = generated_output.sequences[0, len(input_ids.input_ids[0]):]\n",
    "      decoded_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "      # Combine the prompt with the generated text\n",
    "      sentence = decoded_text.replace(\" ,\", \",\").replace(\" 's\", \"'s\").replace(\" .\", \".\").strip()\n",
    "\n",
    "      # Append the generated sentence to the appropriate list\n",
    "      if method == \"top-k\":\n",
    "          generated_sentences_top_k.append(sentence)\n",
    "      else:\n",
    "          generated_sentences_top_p.append(sentence)\n",
    "\n",
    "# Print results\n",
    "print(\"===== Top-K Sampling Output =====\")\n",
    "print()\n",
    "for idx,sentence in enumerate(generated_sentences_top_k):\n",
    "    print(f\"{idx}. {sentence}\")\n",
    "print()\n",
    "print(\"===== Top-P Sampling Output =====\")\n",
    "print()\n",
    "for idx,sentence in enumerate(generated_sentences_top_p):\n",
    "    print(f\"{idx}. {sentence}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def compute_self_bleu(generated_sentences):\n",
    "    total_bleu_score = 0\n",
    "    num_sentences = len(generated_sentences)\n",
    "\n",
    "    for i, hypothesis in enumerate(generated_sentences):\n",
    "        references = [generated_sentences[j] for j in range(num_sentences) if j != i]\n",
    "        bleu_scores = [sentence_bleu([ref.split()], hypothesis.split()) for ref in references]\n",
    "        total_bleu_score += sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "    return total_bleu_score / num_sentences\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = compute_self_bleu(generated_sentences_top_k)\n",
    "print(f\"self-BLEU Score for top_k (k={top_k}): {bleu_score:.4f}\")\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = compute_self_bleu(generated_sentences_top_p)\n",
    "print(f\"self-BLEU Score for top_p (p={top_p}): {bleu_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvI2LvarYe-M"
   },
   "source": [
    "## Q5: t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "######################## (Q5.2 ~ 5.3) ########################\n",
    "# Sentences with different meanings of words\n",
    "sentences = [\n",
    "    \"I ate a fresh apple.\",  # Apple (fruit)\n",
    "    \"Apple released the new iPhone.\",  # Apple (company)\n",
    "    \"I peeled an orange and ate it.\",  # Orange (fruit)\n",
    "    \"The Orange network has great coverage.\",  # Orange (telecom)\n",
    "    \"Microsoft announced a new update.\",  # Microsoft (company)\n",
    "    \"Banana is my favorite fruit.\",  # Banana (fruit)\n",
    "]\n",
    "\n",
    "# Tokenize and move to device\n",
    "inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "# Get hidden states\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "hidden_states = outputs.hidden_states[-1]  # Extract last layer embeddings\n",
    "\n",
    "# Compute sentence-level embeddings (mean pooling)\n",
    "sentence_embeddings = hidden_states.mean(dim=1).cpu().numpy()\n",
    "\n",
    "# Words to visualize\n",
    "word_labels = [\n",
    "    \"Apple (fruit)\", \"Apple (company)\",\n",
    "    \"Orange (fruit)\", \"Orange (telecom)\",\n",
    "    \"Microsoft (company)\", \"Banana (fruit)\"\n",
    "]\n",
    "\n",
    "# Reduce to 2D using t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=2, random_state=42)\n",
    "embeddings_2d = tsne.fit_transform(sentence_embeddings)\n",
    "\n",
    "# Plot the embeddings\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = [\"red\", \"blue\", \"orange\", \"purple\", \"green\", \"brown\"]\n",
    "for i, label in enumerate(word_labels):\n",
    "    plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1], color=colors[i], s=100)\n",
    "    plt.text(embeddings_2d[i, 0] + 0.1, embeddings_2d[i, 1] + 0.1, label, fontsize=12, color=colors[i])\n",
    "\n",
    "plt.xlabel(\"t-SNE Dim 1\")\n",
    "plt.ylabel(\"t-SNE Dim 2\")\n",
    "plt.title(\"t-SNE Visualization of Word Embeddings\")\n",
    "plt.show()\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYDqomF2YWyX"
   },
   "source": [
    "## Q6: Observe the Attention Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import trange\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Input prompt for text generation\n",
    "prompt = \"Google is\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")  # Tokenize the input prompt\n",
    "next_token_id = input_ids.input_ids.to(\"cuda\")  # Move input token ids to GPU\n",
    "attention_mask = input_ids.attention_mask.to(\"cuda\")  # Move attention mask to GPU\n",
    "cache_position = torch.arange(attention_mask.shape[1], device=\"cuda\")  # Position for the KV cache\n",
    "\n",
    "# Set the number of tokens to generate and other parameters\n",
    "generation_tokens = 15  # Limit for visualization (number of tokens to generate)\n",
    "total_tokens = generation_tokens + next_token_id.size(1) - 1  # Total tokens to handle\n",
    "layer_idx = 10  # Specify the layer index for attention visualization\n",
    "head_idx = 7  # Specify the attention head index to visualize\n",
    "\n",
    "# KV cache setup for caching key/values across time steps\n",
    "from transformers.cache_utils import HybridCache\n",
    "kv_cache = HybridCache(config=model.config, max_batch_size=1, max_cache_len=total_tokens, device=\"cuda\", dtype=torch.float16)\n",
    "\n",
    "generated_tokens = []  # List to store generated tokens\n",
    "attentions = None  # Placeholder to store attention weights\n",
    "\n",
    "num_new_tokens = 0  # Counter for the number of new tokens generated\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Generate tokens and collect attention weights for visualization\n",
    "for num_new_tokens in range(generation_tokens):\n",
    "    with torch.no_grad():  # Disable gradients during inference for efficiency\n",
    "        # Pass the input through the model to get the next token prediction and attention weights\n",
    "        outputs = model(\n",
    "            next_token_id,\n",
    "            attention_mask=attention_mask,\n",
    "            cache_position=cache_position,\n",
    "            use_cache=True,  # Use the KV cache for efficiency\n",
    "            past_key_values=kv_cache,  # Provide the cached key-value pairs for fast inference\n",
    "            output_attentions=True  # Enable the extraction of attention weights\n",
    "        )\n",
    "    ######################## TODO (Q6.1 ~ 6.4) ########################\n",
    "    ### You can refer to https://huggingface.co/docs/transformers/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput.attentions to see the structure of model output attentions\n",
    "    # Get the logits for the last generated token from outputs\n",
    "    logits = outputs.logits[:, -1, :]\n",
    "    # Extract the attention scores from the model's outputs\n",
    "    attention_scores = outputs.attentions\n",
    "    ###################################################################\n",
    "\n",
    "    # Extract attention weights for the specified layer and head\n",
    "    last_layer_attention = attention_scores[layer_idx][0][head_idx].detach().cpu().numpy()\n",
    "\n",
    "    # If it's the first generated token, initialize the attentions array\n",
    "    if num_new_tokens == 0:\n",
    "        attentions = last_layer_attention\n",
    "    else:\n",
    "        # Append the current attention weights to the existing array\n",
    "        attentions = np.append(attentions, last_layer_attention, axis=0)\n",
    "\n",
    "    # Choose the next token to generate based on the highest probability (logits)\n",
    "    next_token_id = logits.argmax(dim=-1)\n",
    "    generated_tokens.append(next_token_id.item())  # Add the token ID to the generated tokens list\n",
    "\n",
    "    # Update the attention mask and next token ID for the next iteration\n",
    "    attention_mask = torch.cat([attention_mask, torch.ones(1, 1, device=\"cuda\")], dim=-1)  # Add a new attention mask for the generated token\n",
    "    next_token_id = next_token_id.unsqueeze(0)  # Convert the token ID to the required shape\n",
    "\n",
    "    # Update the KV cache with the new past key-values\n",
    "    kv_cache = outputs.past_key_values\n",
    "    cache_position = cache_position[-1:] + 1  # Update the cache position for the next iteration\n",
    "\n",
    "# Decode the generated tokens into human-readable text\n",
    "generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "full_text = prompt + generated_text  # Combine the prompt with the generated text\n",
    "\n",
    "# Tokenize all the generated text (prompt + generated)\n",
    "tokens = tokenizer.tokenize(full_text)\n",
    "\n",
    "# Function to plot a heatmap of attention weights\n",
    "def plot_attention(attn_matrix, tokens, title=\"Attention Heatmap\"):\n",
    "    plt.figure(figsize=(10, 8))  # Set the figure size\n",
    "    sns.heatmap(attn_matrix, xticklabels=tokens, yticklabels=tokens, cmap=\"viridis\", annot=False)  # Plot the attention matrix as a heatmap\n",
    "    plt.xlabel(\"Key Tokens\")\n",
    "    plt.ylabel(\"Query Tokens\")\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility\n",
    "    plt.yticks(rotation=0)  # Rotate y-axis labels\n",
    "    plt.show()\n",
    "\n",
    "# Plot the attention heatmap for the last generated token\n",
    "plot_attention(attentions, tokens, title=f\"Attention Weights for Generated Token of Layer {layer_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zz2z5Q4TYlyE"
   },
   "source": [
    "## Q7: Observe the Activation Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2li0_FBwbit"
   },
   "source": [
    "The following code is referred from official Gemma tutorials: [Gemma Tutorial From Scratch](https://colab.research.google.com/drive/17dQFYUYnuKnP6OwQPH9v_GSYUW5aj-Rp#scrollTo=2-i7YRVLgKoT) and [SAELens](https://github.com/jbloomAus/SAELens/blob/main/tutorials/tutorial_2_0.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sae-lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens import SAE\n",
    "\n",
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release = \"gemma-scope-2b-pt-res-canonical\",\n",
    "    sae_id = \"layer_20/width_16k/canonical\",\n",
    ")\n",
    "\n",
    "print(sae, cfg_dict, sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "html_template = \"https://neuronpedia.org/{}/{}/{}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "\n",
    "def get_dashboard_html(sae_release = \"gemma-2-2b\", sae_id=\"20-gemmascope-res-16k\", feature_idx=0):\n",
    "    return html_template.format(sae_release, sae_id, feature_idx)\n",
    "\n",
    "########################## TODO (Q7.1) ############################\n",
    "html = get_dashboard_html(sae_release = \"gemma-2-2b\", sae_id=\"20-gemmascope-res-16k\", feature_idx=10004)\n",
    "IFrame(html, width=1200, height=600)\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51VLXHjtGRLN"
   },
   "source": [
    "## Q7.2~7.3: Maximum activations comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## (Q7.2 ~ 7.3) ########################\n",
    "\n",
    "def get_max_activation(model, tokenizer, sae, prompt, feature_idx=10004):\n",
    "    \"\"\"\n",
    "    Computes the maximum activation of a specific feature in a Sparse Autoencoder (SAE)\n",
    "    for a given prompt.\n",
    "\n",
    "    Args:\n",
    "        model: The Transformer model used for generating hidden states.\n",
    "        tokenizer: The tokenizer for encoding the prompt.\n",
    "        sae: The Sparse Autoencoder for encoding hidden states.\n",
    "        prompt (str): The input text prompt.\n",
    "        feature_idx (int, optional): The index of the feature in SAE. Defaults to 10004.\n",
    "\n",
    "    Returns:\n",
    "        float: The maximum activation value for the specified feature index.\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    sae.to(device)\n",
    "\n",
    "    # Tokenize the input prompt and get model outputs\n",
    "    tokens = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model(tokens, output_hidden_states=True)\n",
    "\n",
    "    # Extract hidden states from the specified layer\n",
    "    hidden_states = outputs.hidden_states[sae.cfg.hook_layer]\n",
    "\n",
    "    # Encode hidden states using SAE\n",
    "    sae_in = hidden_states\n",
    "    feature_acts = sae.encode(sae_in).squeeze()  # Shape: (batch_size * seq_len, num_features)\n",
    "    feature_acts = feature_acts.reshape(-1, feature_acts.shape[-1])\n",
    "\n",
    "    # Compute max activation for the specified feature index\n",
    "    max_activation = -float(\"inf\")\n",
    "    batch_max_activation = feature_acts[:, feature_idx].max().item()\n",
    "    max_activation = max(max_activation, batch_max_activation)\n",
    "\n",
    "    # Plot activation distribution\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(feature_acts[:, feature_idx].cpu().detach().numpy(), bins=50, alpha=0.75, color='blue', edgecolor='black')\n",
    "    plt.xlabel(f\"Activation values (Feature {feature_idx})\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"Activation Distribution for Feature {feature_idx} - Prompt: '{prompt}'\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return max_activation\n",
    "\n",
    "feature_idx = 10004\n",
    "# Define the prompts\n",
    "prompt_a = \"Time travel offers me the opportunity to correct past errors, but it comes with its own set of risks.\"\n",
    "prompt_b = \"I accept that my decisions shape my future, and though mistakes are inevitable, they define who I become.\"\n",
    "\n",
    "# Calculate the maximum activations for each prompt using the feature index\n",
    "max_activation_a = get_max_activation(model, tokenizer, sae, prompt_a, feature_idx=feature_idx)\n",
    "max_activation_b = get_max_activation(model, tokenizer, sae, prompt_b, feature_idx=feature_idx)\n",
    "\n",
    "# Print the comparison\n",
    "print(f\"max_activation for prompt_a: {max_activation_a}\")\n",
    "print(f\"max_activation for prompt_b: {max_activation_b}\")\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFg9hOKzGW8y"
   },
   "source": [
    "## Q7.4~7.6: Activation distribution for specific layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_token_activations(model, tokenizer, sae, prompt, feature_idx=10004, layer_idx=0):\n",
    "    \"\"\"\n",
    "    Plots activations for each token in a specific layer.\n",
    "\n",
    "    Args:\n",
    "        model: The transformer model.\n",
    "        tokenizer: Tokenizer for encoding input text.\n",
    "        sae: Sparse Autoencoder model.\n",
    "        prompt: Input text string.\n",
    "        feature_idx: Index of the feature to analyze.\n",
    "        layer_idx: Layer to analyze (None uses sae.cfg.hook_layer).\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    sae.to(device)\n",
    "\n",
    "    # Tokenize input and get model output\n",
    "    tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    token_ids = tokens[\"input_ids\"].to(device)\n",
    "    token_list = tokenizer.convert_ids_to_tokens(token_ids.squeeze().tolist())\n",
    "\n",
    "    outputs = model(token_ids, output_hidden_states=True)\n",
    "\n",
    "    # Choose layer\n",
    "    layer_idx = layer_idx if layer_idx is not None else sae.cfg.hook_layer\n",
    "    hidden_states = outputs.hidden_states[layer_idx]\n",
    "\n",
    "    # Pass through SAE\n",
    "    sae_in = hidden_states\n",
    "    feature_acts = sae.encode(sae_in).squeeze()  # (batch_size, seq_len, num_features)\n",
    "    print(f\"feature_acts shape: {feature_acts.shape}\")\n",
    "\n",
    "    # Extract activations for the chosen feature\n",
    "    activations = feature_acts[:, feature_idx].squeeze().cpu().detach().numpy()\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(range(len(token_list)), activations, color='blue', alpha=0.7)\n",
    "    plt.xticks(range(len(token_list)), token_list, rotation=45)\n",
    "    plt.xlabel(\"Tokens\")\n",
    "    plt.ylabel(f\"Activation Value (Feature {feature_idx})\")\n",
    "    plt.title(f\"Token-wise Activations for Layer {layer_idx}\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "######################## (Q7.4 ~ 7.6) ########################\n",
    "# Simply observe the figure\n",
    "layer_idx = 24\n",
    "prompt = \"Time travel will become a reality as technology continues to advance.\"\n",
    "plot_token_activations(model, tokenizer, sae, prompt_a, feature_idx, layer_idx)\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwLP2sXZGcrb"
   },
   "source": [
    "## Q7.7~7.9: Activation distribution for specific token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layer_activations(model, tokenizer, sae, prompt, token_idx=0, feature_idx=10004):\n",
    "    \"\"\"\n",
    "    Plots activations of a specific token across all layers.\n",
    "\n",
    "    Args:\n",
    "        model: The transformer model.\n",
    "        tokenizer: Tokenizer for encoding input text.\n",
    "        sae: Sparse Autoencoder model.\n",
    "        prompt: Input text string.\n",
    "        token_idx: Index of the token to analyze.\n",
    "        feature_idx: Index of the feature to analyze.\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    sae.to(device)\n",
    "\n",
    "    # Tokenize input and get model output\n",
    "    tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    token_ids = tokens[\"input_ids\"].to(device)\n",
    "    token_list = tokenizer.convert_ids_to_tokens(token_ids.squeeze().tolist())\n",
    "\n",
    "    outputs = model(token_ids, output_hidden_states=True)\n",
    "\n",
    "    # Collect activations across all layers\n",
    "    num_layers = len(outputs.hidden_states)\n",
    "    activations = []\n",
    "\n",
    "    for layer_idx in range(num_layers):\n",
    "        hidden_states = outputs.hidden_states[layer_idx]\n",
    "        sae_in = hidden_states\n",
    "        feature_acts = sae.encode(sae_in).squeeze()  # (batch_size, seq_len, num_features)\n",
    "        # print(f\"feature_acts shape: {feature_acts.shape}\")\n",
    "        activations.append(feature_acts[token_idx, feature_idx].item())\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(num_layers), activations, marker=\"o\", linestyle=\"-\", color=\"blue\")\n",
    "    plt.xlabel(\"Layer\")\n",
    "    plt.ylabel(f\"Activation Value (Feature {feature_idx})\")\n",
    "    plt.title(f\"Activation Across Layers for Token '{token_list[token_idx]}'\")\n",
    "    plt.xticks(range(num_layers))\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "######################## (Q7.7 ~ 7.9) ########################\n",
    "# Alter the token index to observe the figure\n",
    "token_idx = 1\n",
    "prompt = \"Time travel will become a reality as technology continues to advance.\"\n",
    "plot_layer_activations(model, tokenizer, sae, prompt, token_idx)\n",
    "###################################################################"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "014a75d4f0c7420ba2af9aa04fb56b20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd243b59061547b1b7306ee281f3583b",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_856605e12c794c0789f0bc32ba1e6c8a",
      "value": 2
     }
    },
    "07de9725c26f410fa07cc40b8375ea66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0aeb3bff4b9342b5bb4e7b35f5e7c0a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "10e5a9fb077a4c42bf9de00ea9ed72c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13d0cf7b95ba4f02b501d9e8ee79bbcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "16d4ca8d2bae4d4ca74d698da0c060da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1847b5865e2549ec855f4192400edf08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f22a60ad71047938495cbfa9d8774b5",
      "max": 90870598,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_16d4ca8d2bae4d4ca74d698da0c060da",
      "value": 90870598
     }
    },
    "1c2092d6e24a49909a3b4a2a22c45b61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "24744a4a6d1646f39fc78a5e9485d18d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fdc1117051644740a9c1cf20a72cc10e",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cae9bad14ecb4d50aa2c72fb802f9c11",
      "value": 112
     }
    },
    "28b0fa53b9c84e13a891c3cfd7654fc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bc9619b24b6b4843a45b7653f5419f59",
       "IPY_MODEL_1847b5865e2549ec855f4192400edf08",
       "IPY_MODEL_6ff0a2b4987e472083a1ecbe2ceacb8d"
      ],
      "layout": "IPY_MODEL_10e5a9fb077a4c42bf9de00ea9ed72c4"
     }
    },
    "2edd4fe965da491882656effd404e28a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31ce17746df84e84893b396d6d500b43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35b33e3ca09443a0a26b116e1d2ab81b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35c5ae9c238c437d904cefe90aeb5a7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0d7f6f928d44cbc9a253f690280372c",
      "placeholder": "​",
      "style": "IPY_MODEL_ba06d65c62b0436c9ea6bc8cf0af0d4e",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "387a49609e60436e95e8adb98615f928": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_35c5ae9c238c437d904cefe90aeb5a7f",
       "IPY_MODEL_24744a4a6d1646f39fc78a5e9485d18d",
       "IPY_MODEL_4e03b69593714557b543287c915b0e74"
      ],
      "layout": "IPY_MODEL_5dd7793718bf40728d00b641e17b6a91"
     }
    },
    "3b1a41f20bb046c1b3724a173e1e0dbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f45e3d67e18416aa02c26866ed523e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41f8566c468e4c64ae269821eaaf7a41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "460915aa733e40c8bc22505b99dfc68f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "46ca0f1d360142a9a1fa9d5b723911e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e03b69593714557b543287c915b0e74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5487265a3b914c6dac16096959c4dd11",
      "placeholder": "​",
      "style": "IPY_MODEL_41f8566c468e4c64ae269821eaaf7a41",
      "value": " 112/112 [00:00&lt;00:00, 10.2kB/s]"
     }
    },
    "509ae96c6a6041ccb56b06d57f7ed223": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5487265a3b914c6dac16096959c4dd11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "575f2ec2a7054d4e8cf803b0a7db4e14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_93d12794e3cd443cb837024232d9a751",
       "IPY_MODEL_014a75d4f0c7420ba2af9aa04fb56b20",
       "IPY_MODEL_bf3bcfc1fae143148a513be2bec412a2"
      ],
      "layout": "IPY_MODEL_6849b8a95645457b983a5a03ff0b3d2b"
     }
    },
    "5dd7793718bf40728d00b641e17b6a91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "634b8e6fae2b4a80b1bbb035fff74e8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6849b8a95645457b983a5a03ff0b3d2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d5cb5f6b33e448c92300915e852e4fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6eb8a58059eb44a9808d30aa2509a170": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3017acd8da54f6db029328bd13507bc",
      "placeholder": "​",
      "style": "IPY_MODEL_cbccf205aa334497aaca684cf5ab5cfc",
      "value": " 316/316 [00:00&lt;00:00, 29.0kB/s]"
     }
    },
    "6fe38793e7cb4886aa3cc34964612533": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d5cb5f6b33e448c92300915e852e4fb",
      "max": 316,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_13d0cf7b95ba4f02b501d9e8ee79bbcd",
      "value": 316
     }
    },
    "6ff0a2b4987e472083a1ecbe2ceacb8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46ca0f1d360142a9a1fa9d5b723911e8",
      "placeholder": "​",
      "style": "IPY_MODEL_634b8e6fae2b4a80b1bbb035fff74e8e",
      "value": " 90.9M/90.9M [00:01&lt;00:00, 70.1MB/s]"
     }
    },
    "786e809944f54c7ab84e76acd8abab47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2edd4fe965da491882656effd404e28a",
      "placeholder": "​",
      "style": "IPY_MODEL_b335dd14f42a447283079210952abc6b",
      "value": " 794/794 [00:00&lt;00:00, 64.0kB/s]"
     }
    },
    "7a0c4b694edb466aa2ee25915c32d175": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84ef110effb74f858ba3bfb952cf2959": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a82003d73e084252a40d440caedbae11",
       "IPY_MODEL_6fe38793e7cb4886aa3cc34964612533",
       "IPY_MODEL_6eb8a58059eb44a9808d30aa2509a170"
      ],
      "layout": "IPY_MODEL_dba72f7b75454ebe95c1e2a0fe4fde39"
     }
    },
    "856605e12c794c0789f0bc32ba1e6c8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8c8dfb6dc9594ad58b0b4d235266ce88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7386ee24577421d9a69128f703e580e",
      "placeholder": "​",
      "style": "IPY_MODEL_0aeb3bff4b9342b5bb4e7b35f5e7c0a8",
      "value": "vocab.txt: 100%"
     }
    },
    "8eaef3186851403e86a47068624d4e6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c97f7aa7122244ccaf74f6ed84a261e0",
      "placeholder": "​",
      "style": "IPY_MODEL_3f45e3d67e18416aa02c26866ed523e4",
      "value": "config.json: 100%"
     }
    },
    "93d12794e3cd443cb837024232d9a751": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31ce17746df84e84893b396d6d500b43",
      "placeholder": "​",
      "style": "IPY_MODEL_c866b04cd19b489981cc2d6a93f712ba",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "9581e17b2e644b269037f0233cf9bf66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a0c4b694edb466aa2ee25915c32d175",
      "placeholder": "​",
      "style": "IPY_MODEL_3b1a41f20bb046c1b3724a173e1e0dbe",
      "value": " 232k/232k [00:00&lt;00:00, 18.0MB/s]"
     }
    },
    "9f22a60ad71047938495cbfa9d8774b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3d0adaa8c144424941b3a0bd89fa02e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a82003d73e084252a40d440caedbae11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed4c9fdfbf03404089914998b4a28f8e",
      "placeholder": "​",
      "style": "IPY_MODEL_df699a6fec3b4686be605ad144f8c9b7",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "b3017acd8da54f6db029328bd13507bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b335dd14f42a447283079210952abc6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba06d65c62b0436c9ea6bc8cf0af0d4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bc2dd8c0352b4e25bd1fcb934f597380": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc9619b24b6b4843a45b7653f5419f59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc2dd8c0352b4e25bd1fcb934f597380",
      "placeholder": "​",
      "style": "IPY_MODEL_35b33e3ca09443a0a26b116e1d2ab81b",
      "value": "model.safetensors: 100%"
     }
    },
    "bf3bcfc1fae143148a513be2bec412a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de604fa04de24940a3f3fd6de3485b52",
      "placeholder": "​",
      "style": "IPY_MODEL_460915aa733e40c8bc22505b99dfc68f",
      "value": " 2/2 [00:34&lt;00:00, 14.57s/it]"
     }
    },
    "c0d7f6f928d44cbc9a253f690280372c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c866b04cd19b489981cc2d6a93f712ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c97f7aa7122244ccaf74f6ed84a261e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cae9bad14ecb4d50aa2c72fb802f9c11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cbccf205aa334497aaca684cf5ab5cfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd62d298cffe47d4901d6bd0e214c9db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8c8dfb6dc9594ad58b0b4d235266ce88",
       "IPY_MODEL_e8acc4e908754cd5be877101f175a5a3",
       "IPY_MODEL_9581e17b2e644b269037f0233cf9bf66"
      ],
      "layout": "IPY_MODEL_ffecf6c85a894c63898a998f3b62bb56"
     }
    },
    "d8a9049a875142d4a53e2a6b6b43f553": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3d0adaa8c144424941b3a0bd89fa02e",
      "max": 794,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_509ae96c6a6041ccb56b06d57f7ed223",
      "value": 794
     }
    },
    "dba72f7b75454ebe95c1e2a0fe4fde39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddaa36a812bc4d85a55a5068821d42e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de604fa04de24940a3f3fd6de3485b52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df699a6fec3b4686be605ad144f8c9b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e7386ee24577421d9a69128f703e580e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8acc4e908754cd5be877101f175a5a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07de9725c26f410fa07cc40b8375ea66",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1c2092d6e24a49909a3b4a2a22c45b61",
      "value": 231508
     }
    },
    "ed4c9fdfbf03404089914998b4a28f8e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f527f0648ef0476fb0483d47d143e129": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8eaef3186851403e86a47068624d4e6e",
       "IPY_MODEL_d8a9049a875142d4a53e2a6b6b43f553",
       "IPY_MODEL_786e809944f54c7ab84e76acd8abab47"
      ],
      "layout": "IPY_MODEL_ddaa36a812bc4d85a55a5068821d42e4"
     }
    },
    "fd243b59061547b1b7306ee281f3583b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdc1117051644740a9c1cf20a72cc10e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffecf6c85a894c63898a998f3b62bb56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
